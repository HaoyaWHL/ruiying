{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2266446,"sourceType":"datasetVersion","datasetId":1364422}],"dockerImageVersionId":30236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 원본 출처: https://www.kaggle.com/code/salimhammadi07/pcb-defect-detection","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.16934Z","iopub.execute_input":"2022-11-27T14:18:19.170404Z","iopub.status.idle":"2022-11-27T14:18:19.174903Z","shell.execute_reply.started":"2022-11-27T14:18:19.170358Z","shell.execute_reply":"2022-11-27T14:18:19.17375Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nfrom tqdm import tqdm\nimport argparse\nimport glob\nimport xml.etree.ElementTree as ET \nimport cv2\nimport ast\nimport numpy as np\n\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.image as immg\n\nimport random\n\nimport torch\n\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as T\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\n\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-27T14:18:19.182469Z","iopub.execute_input":"2022-11-27T14:18:19.182718Z","iopub.status.idle":"2022-11-27T14:18:19.191465Z","shell.execute_reply.started":"2022-11-27T14:18:19.182695Z","shell.execute_reply":"2022-11-27T14:18:19.190146Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install albumentations==0.4.6\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.196925Z","iopub.execute_input":"2022-11-27T14:18:19.197589Z","iopub.status.idle":"2022-11-27T14:18:19.203158Z","shell.execute_reply.started":"2022-11-27T14:18:19.197466Z","shell.execute_reply":"2022-11-27T14:18:19.20179Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# I. Generate CSV","metadata":{}},{"cell_type":"code","source":"path_an = \"../input/pcb-defects/PCB_DATASET/Annotations\"\nprint(path_an)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.21085Z","iopub.execute_input":"2022-11-27T14:18:19.211159Z","iopub.status.idle":"2022-11-27T14:18:19.216276Z","shell.execute_reply.started":"2022-11-27T14:18:19.211128Z","shell.execute_reply":"2022-11-27T14:18:19.215444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = {\n            \"xmin\":[],\n            \"ymin\":[],   \n            \"xmax\":[],\n            \"ymax\":[],\n            \"class\":[],    \n            \"file\":[],\n            \"width\":[],\n            \"height\":[],\n           }\nall_files = []\nfor path, subdirs, files in os.walk(path_an):\n#     print([path, subdirs, files])\n    for name in files:\n        all_files.append(os.path.join(path, name))\n\n# print(all_files)       \nprint(type(dataset))\nprint(dataset)\n                ","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.222526Z","iopub.execute_input":"2022-11-27T14:18:19.222821Z","iopub.status.idle":"2022-11-27T14:18:19.245442Z","shell.execute_reply.started":"2022-11-27T14:18:19.222785Z","shell.execute_reply":"2022-11-27T14:18:19.244587Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for anno in all_files:\n    # print(anno)\n    tree = ET.parse(anno)\n    \n    for elem in tree.iter():\n        # print(elem)\n        \n        if 'size' in elem.tag:\n            # print('[size] in elem.tag ==> list(elem)\\n'), print(list(elem))\n            for attr in list(elem):\n                if 'width' in attr.tag: \n                    width = int(round(float(attr.text)))\n                if 'height' in attr.tag:\n                    height = int(round(float(attr.text)))    \n\n        if 'object' in elem.tag:\n            # print('[object] in elem.tag ==> list(elem)\\n'), print(list(elem))\n            for attr in list(elem):\n                \n                # print('attr = %s\\n' % attr)\n                if 'name' in attr.tag:\n                    name = attr.text                 \n                    dataset['class']+=[name]\n                    dataset['width']+=[width]\n                    dataset['height']+=[height] \n                    dataset['file']+=[anno.split('/')[-1][0:-4]] \n                            \n                if 'bndbox' in attr.tag:\n                    for dim in list(attr):\n                        if 'xmin' in dim.tag:\n                            xmin = int(round(float(dim.text)))\n                            dataset['xmin']+=[xmin]\n                        if 'ymin' in dim.tag:\n                            ymin = int(round(float(dim.text)))\n                            dataset['ymin']+=[ymin]                                \n                        if 'xmax' in dim.tag:\n                            xmax = int(round(float(dim.text)))\n                            dataset['xmax']+=[xmax]                                \n                        if 'ymax' in dim.tag:\n                            ymax = int(round(float(dim.text)))\n                            dataset['ymax']+=[ymax]         ","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.247144Z","iopub.execute_input":"2022-11-27T14:18:19.24778Z","iopub.status.idle":"2022-11-27T14:18:19.7432Z","shell.execute_reply.started":"2022-11-27T14:18:19.247747Z","shell.execute_reply":"2022-11-27T14:18:19.742338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data=pd.DataFrame(dataset)\ndata","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.744501Z","iopub.execute_input":"2022-11-27T14:18:19.744832Z","iopub.status.idle":"2022-11-27T14:18:19.767791Z","shell.execute_reply.started":"2022-11-27T14:18:19.7448Z","shell.execute_reply":"2022-11-27T14:18:19.766952Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# II. Reading the CSV file","metadata":{}},{"cell_type":"code","source":"# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\ntrain, test = train_test_split(data, shuffle=True, test_size=0.2, random_state=34)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.770024Z","iopub.execute_input":"2022-11-27T14:18:19.770577Z","iopub.status.idle":"2022-11-27T14:18:19.777422Z","shell.execute_reply.started":"2022-11-27T14:18:19.770514Z","shell.execute_reply":"2022-11-27T14:18:19.776353Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.778876Z","iopub.execute_input":"2022-11-27T14:18:19.779521Z","iopub.status.idle":"2022-11-27T14:18:19.788326Z","shell.execute_reply.started":"2022-11-27T14:18:19.779487Z","shell.execute_reply":"2022-11-27T14:18:19.787227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.78989Z","iopub.execute_input":"2022-11-27T14:18:19.790379Z","iopub.status.idle":"2022-11-27T14:18:19.803883Z","shell.execute_reply.started":"2022-11-27T14:18:19.790259Z","shell.execute_reply":"2022-11-27T14:18:19.803Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.805973Z","iopub.execute_input":"2022-11-27T14:18:19.806642Z","iopub.status.idle":"2022-11-27T14:18:19.818882Z","shell.execute_reply.started":"2022-11-27T14:18:19.806609Z","shell.execute_reply":"2022-11-27T14:18:19.817923Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes_la = {\"missing_hole\": 0, \"mouse_bite\": 1, \"open_circuit\":2, \"short\": 3, 'spur': 4,'spurious_copper':5}\n\ntrain[\"class\"] = train[\"class\"].apply(lambda x: classes_la[x])\ntest[\"class\"] = test[\"class\"].apply(lambda x: classes_la[x])","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.820425Z","iopub.execute_input":"2022-11-27T14:18:19.820759Z","iopub.status.idle":"2022-11-27T14:18:19.828897Z","shell.execute_reply.started":"2022-11-27T14:18:19.820726Z","shell.execute_reply":"2022-11-27T14:18:19.827926Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.833156Z","iopub.execute_input":"2022-11-27T14:18:19.834049Z","iopub.status.idle":"2022-11-27T14:18:19.845808Z","shell.execute_reply.started":"2022-11-27T14:18:19.834016Z","shell.execute_reply":"2022-11-27T14:18:19.844816Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.847203Z","iopub.execute_input":"2022-11-27T14:18:19.847623Z","iopub.status.idle":"2022-11-27T14:18:19.858402Z","shell.execute_reply.started":"2022-11-27T14:18:19.84759Z","shell.execute_reply":"2022-11-27T14:18:19.857426Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# III. Visualization ","metadata":{}},{"cell_type":"code","source":"# PJC (deep copy)\ndf = train.copy()\n\ndf_grp = df.groupby(['file'])\nprint(df_grp)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.859948Z","iopub.execute_input":"2022-11-27T14:18:19.860603Z","iopub.status.idle":"2022-11-27T14:18:19.868183Z","shell.execute_reply.started":"2022-11-27T14:18:19.86057Z","shell.execute_reply":"2022-11-27T14:18:19.867194Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_grp.size()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.869848Z","iopub.execute_input":"2022-11-27T14:18:19.870599Z","iopub.status.idle":"2022-11-27T14:18:19.88028Z","shell.execute_reply.started":"2022-11-27T14:18:19.870564Z","shell.execute_reply":"2022-11-27T14:18:19.879265Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DataFrameGroupBy (https://steadiness-193.tistory.com/47)\n# .. 효과: 튜플 형태로 (그룹이름, 그룹별 데이터셋(데이터프레임)) 형태로 구성됨\n# .. 순회 방법: for key, group in grouped: print(group.head())\n# .. 특정 멤버 획득: group = grouped.get_group('group_name'), group.head()\n#\n# 예시) 01_missing_hole_01\nimage_name = '01_missing_hole_02'\nimage_group = df_grp.get_group(image_name)\nprint(image_group)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.882075Z","iopub.execute_input":"2022-11-27T14:18:19.882432Z","iopub.status.idle":"2022-11-27T14:18:19.891498Z","shell.execute_reply.started":"2022-11-27T14:18:19.8824Z","shell.execute_reply":"2022-11-27T14:18:19.890501Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbox = image_group.loc[:,['xmin', 'ymin', 'xmax', 'ymax']]\nprint([bbox, type(bbox)])","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.892658Z","iopub.execute_input":"2022-11-27T14:18:19.893627Z","iopub.status.idle":"2022-11-27T14:18:19.903444Z","shell.execute_reply.started":"2022-11-27T14:18:19.893592Z","shell.execute_reply":"2022-11-27T14:18:19.902374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Matplotlib Tutorial - 파이썬으로 데이터 시각화하기 (https://wikidocs.net/book/5011)\n# .. 24. Matplotlib 여러 개의 그래프 그리기 subplot(..) (https://wikidocs.net/141537)\n# .. plt.subplots() 사용하기 (https://wikidocs.net/141561)\n# .... fig, ax = plt.subplots() : (1)figure(fig)과 (2)subplot(ax) 객체를 생성해서 튜플의 형태로 반환\n# .. 파이썬 subplots 좀 더 잘 사용해보기 (https://data-newbie.tistory.com/447)\n# .... (1)스케일 조정하기, (2)그래프 안에 더 작은 그래프 넣기 등","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.904882Z","iopub.execute_input":"2022-11-27T14:18:19.905339Z","iopub.status.idle":"2022-11-27T14:18:19.910465Z","shell.execute_reply.started":"2022-11-27T14:18:19.905304Z","shell.execute_reply":"2022-11-27T14:18:19.909353Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 파일 이미지 그리기\n# .. 입력: image_name(이미지 파일명) //'01_missing_hole_01', '12_spurious_copper_06', ..\ndef plot_image(image_name):\n    print(image_name)\n    image_group = df_grp.get_group(image_name)\n    bbox = image_group.loc[:,['xmin', 'ymin', 'xmax', 'ymax']]\n    path =\"../input/pcb-defects/PCB_DATASET/images/\"\n    if \"missing\" in name.split('_'):\n        path += 'Missing_hole/'\n    if \"mouse\" in name.split('_'):\n        path += 'Mouse_bite/'\n    if \"open\" in name.split('_'):\n        path += 'Open_circuit/'\n    if \"short\" in name.split('_'):\n        path += 'Short/'\n    if \"spur\" in name.split('_'):\n        path += 'Spur/'\n    if \"spurious\" in name.split('_'):\n        path += 'Spurious_copper/'\n   \n    img = immg.imread(path+\"\"+name+'.jpg')\n    fig,ax = plt.subplots(figsize=(18,10))\n    ax.imshow(img,cmap='binary')\n    for i in range(len(bbox)):\n        box = bbox.iloc[i].values\n        print(box)\n        x,y,w,h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n        rect = matplotlib.patches.Rectangle((x,y),w,h,linewidth=1,edgecolor='r',facecolor='none',)\n        # ax.text(*box[:2], image_group[\"class\"].values, verticalalignment='top', color='white', fontsize=13, weight='bold')\n        ax.add_patch(rect)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.912234Z","iopub.execute_input":"2022-11-27T14:18:19.912732Z","iopub.status.idle":"2022-11-27T14:18:19.92709Z","shell.execute_reply.started":"2022-11-27T14:18:19.9127Z","shell.execute_reply":"2022-11-27T14:18:19.926126Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"name = '01_missing_hole_01'\nplot_image(name)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:19.928541Z","iopub.execute_input":"2022-11-27T14:18:19.928891Z","iopub.status.idle":"2022-11-27T14:18:21.456714Z","shell.execute_reply.started":"2022-11-27T14:18:19.928848Z","shell.execute_reply":"2022-11-27T14:18:21.455682Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"name = train.file[500]\nplot_image(name)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:21.458119Z","iopub.execute_input":"2022-11-27T14:18:21.459035Z","iopub.status.idle":"2022-11-27T14:18:22.451641Z","shell.execute_reply.started":"2022-11-27T14:18:21.458972Z","shell.execute_reply":"2022-11-27T14:18:22.450609Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"name = train.file[100]\nplot_image(name)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:22.453075Z","iopub.execute_input":"2022-11-27T14:18:22.453492Z","iopub.status.idle":"2022-11-27T14:18:23.657843Z","shell.execute_reply.started":"2022-11-27T14:18:22.45346Z","shell.execute_reply":"2022-11-27T14:18:23.656834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"name = train.file[105]\nplot_image(name)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:23.659494Z","iopub.execute_input":"2022-11-27T14:18:23.659827Z","iopub.status.idle":"2022-11-27T14:18:24.879429Z","shell.execute_reply.started":"2022-11-27T14:18:23.659795Z","shell.execute_reply":"2022-11-27T14:18:24.878426Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# IV. Creating Custom database","metadata":{}},{"cell_type":"code","source":"#\n# Custom Dataset 클래스 생성 (https://visionhong.tistory.com/4?category=946616)\n# .. (1) torch.utils.data.Dataset을 오버라이드\n# .. (2) 3개 함수 필수 구현: __init__, __len__, __getitem__\n# -----------------\n# 인덱스로 접근할 수 있는 이터레이터 (https://dojang.io/mod/page/view.php?id=2407)\n# .. (1) 클래스에서 __getitem__ 메서드만 구현해도 이터레이터가 되며 __iter__, __next__는 생략해도 됨\n# .. (2) 클래스에서 __getitem__ 메서드를 구현하면 인덱스로 접근할 수 있는 이터레이터가 됨\n#\nclass fcbData(object):\n    def __init__(self, df, IMG_DIR, transforms): \n        self.df = df\n        self.img_dir = IMG_DIR\n        self.image_ids = self.df['file'].unique().tolist()\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        a = ''\n        if \"missing\" in image_id.split('_'):\n            a = 'Missing_hole/'\n        elif \"mouse\" in image_id.split('_'):\n            a = 'Mouse_bite/'\n        elif \"open\" in image_id.split('_'):\n            a = 'Open_circuit/'\n        elif \"short\" in image_id.split('_'):\n            a = 'Short/'\n        elif \"spur\" in image_id.split('_'):\n            a = 'Spur/'\n        elif \"spurious\" in image_id.split('_'):\n            a = 'Spurious_copper/'\n        image_values = self.df[self.df['file'] == image_id]\n        image = cv2.imread(self.img_dir+a+image_id+\".jpg\",cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        \n        boxes = image_values[['xmin', 'ymin', 'xmax', 'ymax']].to_numpy()\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        \n        labels = image_values[\"class\"].values\n        labels = torch.tensor(labels)\n        \n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([idx])\n        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n        target['iscrowd'] = torch.zeros(len(classes_la), dtype=torch.int64)\n\n        if self.transforms:\n            sample = {\n                'image': image,\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n        \n            sample = self.transforms(**sample)\n            image = sample['image']\n            \n            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n\n        return torch.tensor(image), target, image_id","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:24.881104Z","iopub.execute_input":"2022-11-27T14:18:24.88146Z","iopub.status.idle":"2022-11-27T14:18:24.899372Z","shell.execute_reply.started":"2022-11-27T14:18:24.881428Z","shell.execute_reply":"2022-11-27T14:18:24.898345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the image transformations. We'll use albumentations package: https://albumentations.ai/\n","metadata":{}},{"cell_type":"code","source":"# pip install -U albumentations","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:24.90052Z","iopub.execute_input":"2022-11-27T14:18:24.901262Z","iopub.status.idle":"2022-11-27T14:18:24.91234Z","shell.execute_reply.started":"2022-11-27T14:18:24.901228Z","shell.execute_reply":"2022-11-27T14:18:24.911358Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_train_transform():\n    return A.Compose([\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\ndef get_valid_transform():\n    return A.Compose([\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:24.913556Z","iopub.execute_input":"2022-11-27T14:18:24.914534Z","iopub.status.idle":"2022-11-27T14:18:24.926231Z","shell.execute_reply.started":"2022-11-27T14:18:24.914434Z","shell.execute_reply":"2022-11-27T14:18:24.925342Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df는 'df = train.Copy()' (즉, train data의 deep 복사본)\npath =\"../input/pcb-defects/PCB_DATASET/images/\"\nfcb_dataset   = fcbData(df, path, get_train_transform())","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:18:24.931826Z","iopub.execute_input":"2022-11-27T14:18:24.932074Z","iopub.status.idle":"2022-11-27T14:18:24.937482Z","shell.execute_reply.started":"2022-11-27T14:18:24.93205Z","shell.execute_reply":"2022-11-27T14:18:24.936499Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(fcb_dataset[0]), len(fcb_dataset[0]), type(fcb_dataset[0][0]), type(fcb_dataset[0][1]), type(fcb_dataset[0][2])","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:28:46.77344Z","iopub.execute_input":"2022-11-27T14:28:46.774341Z","iopub.status.idle":"2022-11-27T14:28:47.432331Z","shell.execute_reply.started":"2022-11-27T14:28:46.774269Z","shell.execute_reply":"2022-11-27T14:28:47.431232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fcb_dataset[i]는 tuple이므로 배열 인덱스로 참조해야 함\n# .. tuple인 이유는: __get_item__() 함수의 반환값이 튜플이기 때문 (return torch.tensor(image), target, image_id)\n# .. tuple의 원소 참조\n# .... [i][0]: image\n# .... [i][1]: target    //딕셔너리 {boxes, labels, image_id(인덱스 번호), area, iscrowd}\n# .... [i][2]: image_id  //이미지 명칭\nprint([fcb_dataset[0][0], fcb_dataset[0][1], fcb_dataset[0][2]])","metadata":{"execution":{"iopub.status.busy":"2022-11-27T14:38:37.438793Z","iopub.execute_input":"2022-11-27T14:38:37.439174Z","iopub.status.idle":"2022-11-27T14:38:37.832708Z","shell.execute_reply.started":"2022-11-27T14:38:37.439142Z","shell.execute_reply":"2022-11-27T14:38:37.831755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# [Pytorch] Tensor에서 혼동되는 여러 메서드와 함수 (https://subinium.github.io/pytorch-Tensor-Variable/)\n# .. 차원 재구성: 종종 channel 차원을 마지막으로 보내야하는 순간이 존재하고, 연산에 따라 차원 간의 순서를 변경해줄 필요가 있음\n# .... transpose() : 2개의 차원을 변경하는데 사용\n# .... permute() : 모든 차원의 순서를 재배치","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check if the custom dataset object created ealier works","metadata":{}},{"cell_type":"code","source":"# Custom Dataset에 넣어놓은 특정 data 가시화 (image 가시화 후에, 불량 부위 bboxes 가시화)\n# .. 주의: fcb_dataset[i]에서 반환되는 요소는 3개 모두 tensor이므로, 필요시 (1)numpy로 변환하거나 이미지의 경우에는 (2)channel 순서를 변경해야 함(permute(..))\n#\nimg, tar, _ = fcb_dataset[random.randint(0,50)]\nbbox = tar['boxes']\nfig,ax = plt.subplots(figsize=(18,10))\nax.imshow(img.permute(1,2,0).cpu().numpy())\nfor j in tar[\"labels\"].tolist():\n    classes_la = {0:\"missing_hole\", 1: \"mouse_bite\", 2:\"open_circuit\",3: \"short\", 4:'spur',5:'spurious_copper'}\n    l = classes_la[j]\n    for i in range(len(bbox)):\n        box = bbox[i]\n        x,y,w,h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n        rect = matplotlib.patches.Rectangle((x,y),w,h,linewidth=2,edgecolor='r',facecolor='none',)\n        ax.text(*box[:2], l, verticalalignment='top', color='red', fontsize=13, weight='bold')\n        ax.add_patch(rect)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:13.969371Z","iopub.execute_input":"2022-11-24T04:55:13.969744Z","iopub.status.idle":"2022-11-24T04:55:15.912773Z","shell.execute_reply.started":"2022-11-24T04:55:13.969712Z","shell.execute_reply":"2022-11-24T04:55:15.911546Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.914175Z","iopub.execute_input":"2022-11-24T04:55:15.914718Z","iopub.status.idle":"2022-11-24T04:55:15.92207Z","shell.execute_reply.started":"2022-11-24T04:55:15.91468Z","shell.execute_reply":"2022-11-24T04:55:15.921087Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Split data into training and test","metadata":{}},{"cell_type":"code","source":"image_ids = df['file'].unique()\nvalid_ids = image_ids[-665:]\ntrain_ids = image_ids[:-665]\nvalid_df = df[df['file'].isin(valid_ids)]\ntrain_df = df[df['file'].isin(train_ids)]\ntrain_df.shape,valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.92794Z","iopub.execute_input":"2022-11-24T04:55:15.928716Z","iopub.status.idle":"2022-11-24T04:55:15.941002Z","shell.execute_reply.started":"2022-11-24T04:55:15.928633Z","shell.execute_reply":"2022-11-24T04:55:15.93998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# V. Dataloader","metadata":{}},{"cell_type":"code","source":"# PJC (Pytorch Dataloader - (batch) sampler, collate_fn 개념)\n# --- https://comlini8-8.tistory.com/91","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.942765Z","iopub.execute_input":"2022-11-24T04:55:15.94331Z","iopub.status.idle":"2022-11-24T04:55:15.950043Z","shell.execute_reply.started":"2022-11-24T04:55:15.943262Z","shell.execute_reply":"2022-11-24T04:55:15.948962Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.951321Z","iopub.execute_input":"2022-11-24T04:55:15.952198Z","iopub.status.idle":"2022-11-24T04:55:15.964868Z","shell.execute_reply.started":"2022-11-24T04:55:15.952159Z","shell.execute_reply":"2022-11-24T04:55:15.963798Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PJC (파이썬의 Asterisk(*) 이해하기: https://mingrammer.com/understanding-the-asterisk-of-python/)\n# .. '컨테이너 타입의 데이터를 Unpacking 할 때' asterisk(*)가 사용될 수 있음\n\n# collate_fn 정의\ndef collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.966042Z","iopub.execute_input":"2022-11-24T04:55:15.966908Z","iopub.status.idle":"2022-11-24T04:55:15.974329Z","shell.execute_reply.started":"2022-11-24T04:55:15.966872Z","shell.execute_reply":"2022-11-24T04:55:15.973338Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = fcbData(df, path, get_train_transform())\nvalid_dataset = fcbData(df, path, get_valid_transform())\n\n# split the dataset in train and test set\nindices = torch.randperm(len(train_dataset)).tolist()\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=6,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=6,\n    collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.976055Z","iopub.execute_input":"2022-11-24T04:55:15.976407Z","iopub.status.idle":"2022-11-24T04:55:15.990548Z","shell.execute_reply.started":"2022-11-24T04:55:15.976374Z","shell.execute_reply":"2022-11-24T04:55:15.98953Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (PJC) 파이토치 데이터로더 데이터 확인하니 : dataloader, next(iter(dataloader))\n# .. 출처: https://nomalcy.tistory.com/279\nnext(iter(train_data_loader))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:15.992296Z","iopub.execute_input":"2022-11-24T04:55:15.992715Z","iopub.status.idle":"2022-11-24T04:55:17.890207Z","shell.execute_reply.started":"2022-11-24T04:55:15.99268Z","shell.execute_reply":"2022-11-24T04:55:17.889129Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PyTorch 모델 저장 & 로드\n# .. https://tutorials.pytorch.kr/beginner/saving_loading_models.html","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:17.891959Z","iopub.execute_input":"2022-11-24T04:55:17.892276Z","iopub.status.idle":"2022-11-24T04:55:17.897143Z","shell.execute_reply.started":"2022-11-24T04:55:17.892245Z","shell.execute_reply":"2022-11-24T04:55:17.895752Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TORCHVISION 객체 검출 미세조정(FINETUNING) 튜토리얼\n# .. https://tutorials.pytorch.kr/intermediate/torchvision_tutorial.html","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:17.898961Z","iopub.execute_input":"2022-11-24T04:55:17.89984Z","iopub.status.idle":"2022-11-24T04:55:17.908916Z","shell.execute_reply.started":"2022-11-24T04:55:17.899797Z","shell.execute_reply":"2022-11-24T04:55:17.907851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Most pretrained models are trained with a background class, we'll include it in our model, so in that case our number of classes will be 6","metadata":{}},{"cell_type":"code","source":"## num_classes = 6 # + background\nnum_classes = 6\n\n# load a model; pre-trained on COCO\n# .. fpn = 'feature pyramid network'\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:55:52.91846Z","iopub.execute_input":"2022-11-24T04:55:52.918855Z","iopub.status.idle":"2022-11-24T04:56:02.082403Z","shell.execute_reply.started":"2022-11-24T04:55:52.91882Z","shell.execute_reply":"2022-11-24T04:56:02.08137Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:56:08.740558Z","iopub.execute_input":"2022-11-24T04:56:08.740921Z","iopub.status.idle":"2022-11-24T04:56:08.745892Z","shell.execute_reply.started":"2022-11-24T04:56:08.740891Z","shell.execute_reply":"2022-11-24T04:56:08.744825Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\n# [PyTorch tutorial] PyTorch에서 GPU 활용하기 (https://wonder-j.tistory.com/12)\n# .. (1) PyTorch에서 GPU를 활용하는 법은 간단하다. \"모델을 GPU에 넣어주면 됨\"\n#        device = torch.device(\"cuda:0\")\n#        model.to(device)\n# .. (2) 모든 텐서를 GPU에 넣어줌(input, lable 등)\n#        mytensor = my_tensor.to(device)\n#\nmodel.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.0001, weight_decay=0.0005,)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:56:10.594442Z","iopub.execute_input":"2022-11-24T04:56:10.594811Z","iopub.status.idle":"2022-11-24T04:56:10.658584Z","shell.execute_reply.started":"2022-11-24T04:56:10.594778Z","shell.execute_reply":"2022-11-24T04:56:10.657706Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 1","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:56:11.86534Z","iopub.execute_input":"2022-11-24T04:56:11.865703Z","iopub.status.idle":"2022-11-24T04:56:11.870368Z","shell.execute_reply.started":"2022-11-24T04:56:11.865672Z","shell.execute_reply":"2022-11-24T04:56:11.869347Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VI. Training and evaluation","metadata":{}},{"cell_type":"code","source":"train_data_loader","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:56:16.115564Z","iopub.execute_input":"2022-11-24T04:56:16.115928Z","iopub.status.idle":"2022-11-24T04:56:16.124028Z","shell.execute_reply.started":"2022-11-24T04:56:16.115896Z","shell.execute_reply":"2022-11-24T04:56:16.122941Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nbest_epoch = 0\nmin_loss = sys.maxsize\n\nfor epoch in range(num_epochs):\n    tk = tqdm(train_data_loader)\n    model.train();\n    for images, targets, image_ids in tk:\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        \n        tk.set_postfix(train_loss=loss_value)\n    tk.close()\n    \n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n    \n    print(f\"Epoch #{epoch} loss: {loss_value}\") \n        \n    #validation \n    model.eval();\n    with torch.no_grad():\n        tk = tqdm(valid_data_loader)\n        for images, targets, image_ids in tk:\n            images = list(image.to(device) for image in images)\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n            val_output = model(images)\n            val_output = [{k: v.to(device) for k, v in t.items()} for t in val_output]\n            IOU = []\n            for j in range(len(val_output)):\n                a,b = val_output[j]['boxes'].cpu().detach(), targets[j]['boxes'].cpu().detach()\n                chk = torchvision.ops.box_iou(a,b)\n                res = np.nanmean(chk.sum(axis=1)/(chk>0).sum(axis=1))\n                IOU.append(res)\n            tk.set_postfix(IoU=np.mean(IOU))\n        tk.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:56:18.333899Z","iopub.execute_input":"2022-11-24T04:56:18.33428Z","iopub.status.idle":"2022-11-24T05:02:05.489969Z","shell.execute_reply.started":"2022-11-24T04:56:18.334248Z","shell.execute_reply":"2022-11-24T05:02:05.488878Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sample evaluation on validation dataset image","metadata":{}},{"cell_type":"code","source":"img,target,_ = valid_dataset[3]\n# put the model in evaluation mode\nmodel.eval()\nwith torch.no_grad():\n    prediction = model([img.to(device)])[0]\n    \nprint('predicted #boxes: ', len(prediction['boxes']))\nprint('real #boxes: ', len(target['boxes']))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:02:26.161171Z","iopub.execute_input":"2022-11-24T05:02:26.161565Z","iopub.status.idle":"2022-11-24T05:02:26.446807Z","shell.execute_reply.started":"2022-11-24T05:02:26.161531Z","shell.execute_reply":"2022-11-24T05:02:26.445824Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'pcbdetection.pt')","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:02:47.674813Z","iopub.execute_input":"2022-11-24T05:02:47.675212Z","iopub.status.idle":"2022-11-24T05:02:48.079745Z","shell.execute_reply.started":"2022-11-24T05:02:47.675176Z","shell.execute_reply":"2022-11-24T05:02:48.078412Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VII. Evaluation","metadata":{}},{"cell_type":"code","source":"y_true =[]\ny_pred = []\nfor i in range(50):\n    img,target,_ = valid_dataset[i]\n    model.eval()\n    with torch.no_grad():\n        prediction = model([img.to(device)])[0]\n        y_true.append(target['labels'][0])\n        y_pred.append(prediction['labels'][0])\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:02:50.225176Z","iopub.execute_input":"2022-11-24T05:02:50.225602Z","iopub.status.idle":"2022-11-24T05:03:01.794224Z","shell.execute_reply.started":"2022-11-24T05:02:50.225569Z","shell.execute_reply":"2022-11-24T05:03:01.793237Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:05:04.238218Z","iopub.execute_input":"2022-11-24T05:05:04.239129Z","iopub.status.idle":"2022-11-24T05:05:04.254736Z","shell.execute_reply.started":"2022-11-24T05:05:04.23907Z","shell.execute_reply":"2022-11-24T05:05:04.253634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yy_pred = []\nfor v in y_pred:\n    yy_pred.append(v.cpu())","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:12:45.786806Z","iopub.execute_input":"2022-11-24T05:12:45.787216Z","iopub.status.idle":"2022-11-24T05:12:45.793849Z","shell.execute_reply.started":"2022-11-24T05:12:45.787179Z","shell.execute_reply":"2022-11-24T05:12:45.792616Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yy_pred","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:12:47.242876Z","iopub.execute_input":"2022-11-24T05:12:47.24357Z","iopub.status.idle":"2022-11-24T05:12:47.256041Z","shell.execute_reply.started":"2022-11-24T05:12:47.24353Z","shell.execute_reply":"2022-11-24T05:12:47.254919Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:03:09.574107Z","iopub.execute_input":"2022-11-24T05:03:09.575065Z","iopub.status.idle":"2022-11-24T05:03:09.587339Z","shell.execute_reply.started":"2022-11-24T05:03:09.575029Z","shell.execute_reply":"2022-11-24T05:03:09.586101Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_true, yy_pred)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T06:14:26.10874Z","iopub.execute_input":"2022-11-24T06:14:26.109133Z","iopub.status.idle":"2022-11-24T06:14:26.119662Z","shell.execute_reply.started":"2022-11-24T06:14:26.109075Z","shell.execute_reply":"2022-11-24T06:14:26.118517Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# classification_report로 평가 지표 확인하기\n# .. https://blog.naver.com/PostView.naver?blogId=hannaurora&logNo=222498671200&parentCategoryNo=&categoryNo=41&viewDate=&isShowPopularPosts=true&from=search\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_true, yy_pred))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:21:37.24809Z","iopub.execute_input":"2022-11-24T05:21:37.248506Z","iopub.status.idle":"2022-11-24T05:21:37.260706Z","shell.execute_reply.started":"2022-11-24T05:21:37.248473Z","shell.execute_reply":"2022-11-24T05:21:37.259532Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}